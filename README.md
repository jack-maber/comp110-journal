# comp110-journal
## Research Paper 1 - "When does a physical system compute?"
In the first research paper, the overlying theme is what actually defines a computer, a computation, and the physical and theoretical link between the two. As everyone thinks of of a "computer" being the tower under the desk or the laptop jammed into their backpack, this paper tries to break open what actually defines a computer, because as stated in the abstract, "There has been, however,
no consensus on how to tell if a given physical system is acting as a computer or not" and even that "every physical event is a
computation", which even to me seems quite an outlandish claim as even I know that by definition a "physical system" can only really  be defined as a computer if it has the capacity writing and decoding some kind of data so that it can actually carry out a function as a result of that input or output. 

However this paper focuses more on the relation between the aforementioned "physical system" and the "abstract computation/theory" and how we have to have a real world example to explain an abstract theory, especially when explaining physics, which is what the bulk of computational theory is based around at this low level, and this makes perfect sense in any context really as anything without a physical representation can only be explained with an example that exists in the real world, an example given in the paper is "atom is represented as a wave function", everyone should know what an atom is, and where it exists in real world terms, but not everyone knows what a wave function is and where it stands in the real world, and thus this "abstract" theory can be explained a physical representation, which is very important when it comes to understanding the question that the paper is aiming to answer. When it comes down to it, a physical system computes when it has the ability to take a piece of "abstract" data and encode it, and the encoding is not governed purely by the physics of the system, as different systems would be effected differently, also how the computer's data is represented, and stated in the paper, normal semi-conductor based computers rely on the old way of representing "1" with high voltage and "0", and as seen in the highly complex diagrams in the paper, it is of the upmost importance that the relation between the "Physical system" and the way that the "abstract theory" makes it as accurate as possible for the first computation of the data to occur, as otherwise none of the data that follows will make any sense. 

This paper is similar in many ways to paper 3 as it is describing as they are both describing physical theories that can be in someway transferred to computing, with this paper providing a framework to describe when a system is computing and the link between "abstract" and "physical", while Paper 3 proposes a way of measuring the distance objects in 3D space, which can then be transferred into computer programs, as such they both link how real life theories can be transferred and used in computational instances and can be used to great effect. 


## Research Paper 2 - "Experimental Investigations of the Utility of Detailed Flowcharts in Programming "
This paper focuses on the use of Flowcharts and their effectiveness to aid programmers or academics to understand how a program functions. The creators of this paper set out to investigate this by composing a number of separate experiments to see fit they help programmers in different situations that are commonly encountered in computing, such as comprehension and composition of programs, all very important to becoming a competent programmer, and so any help that Flowcharts could provide would be very useful, which is why the creators set out to create a definitive answer.
I was quickly able to infer from the paper that the creators had carried out a lot of research prior to conducting their experiments, even finding that there had been a proposal for a US National standard in 1963, which I found very surprising as I thought that standardising a creative system such as flowcharts would be quite difficult, but then again it was only proposed, previous papers sourced in the paper, such as Weinburg stated that utilizing flowcharts to teach people as they only make sense to the original creator, but again other research infered other results, but there was no concrete evidence to support any of these claims, which was weird as flowcharts to map programs had been around since the infancy of computers, which brings up a similarity between two of the papers, as paper 4 also calls back to a commonly used technique in computing at the time, the go to statement, and they both provide evidence against these two widely used techniques and disprove their usefullness inn certain areas, as the experiments carried out later in the program prove, only during the cretion of programs do flowcharts actually help, whereas in all the other tests it made no difference, or in the case of comprehension it made it easier to have the actual program, which made perfect sense to me as the flowchart becomes redundant, so nothing really outstanding from this research paper, but a good amount of insight into providing concrete evidence,and by covering all of the basic tasks that a programmer will undertake, they've covered all bases, which is a good way of creating solid evidence. 






Utilizing flow charts to teach people is pointless as only the original creator understands them

Easier to create programs - results did not match what was previously proprosed as both groups preformed bascially the same.

Believed before that having a flowchart makes it easier to comprehend programs but their results didn't find this too be true

Helps visually for a short period of time but doesn't help with remembering

Debugging test found no difference along with comprehension of a program

Comprehension again found that having the actual program is more useful than a flowchart and having "redundant info" may hinder the user in understanding the program

## Research Paper 3 - "A Fast Procedure for Computing the Distance Between Complex Objects in Three-Dimensional Space"

Presents a way of computing the "Euclidean" distance ( the length of a shortest line segment
joining the two objects) between objects in 3D space.

Can be applied to a "complex family of shape models" 

"Objects are subject to changes in position and orientation", such as in video games

A lot of maths I don't understand

## Research Paper 4 - "Letters to the editor - Go To Statement Considered Harmful"
